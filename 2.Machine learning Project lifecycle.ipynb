{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63e1c4f",
   "metadata": {},
   "source": [
    "## Machine learning Project lifecycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15957d0b",
   "metadata": {},
   "source": [
    "### Q14. Describe the lifecycle of the machine learning system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2cb8d4",
   "metadata": {},
   "source": [
    "The lifecycle of a machine learning system generally consists of the following steps:\n",
    "\n",
    "- Problem definition: Determine the problem to be solved and how it can be addressed with machine learning.\n",
    "\n",
    "- Data collection: Gather and prepare the data required for training the model.\n",
    "\n",
    "- Data preprocessing: Clean and transform the data to make it suitable for modeling.\n",
    "\n",
    "- **Model selection:** Choose the appropriate machine learning algorithm and configure it for the problem at hand.\n",
    "\n",
    "- Model training: Train the machine learning model on the preprocessed data.\n",
    "\n",
    "- Model evaluation: Assess the performance of the model on a separate data set to verify its accuracy.\n",
    "\n",
    "- Model tuning: Adjust the model's hyperparameters to optimize its performance.\n",
    "\n",
    "- Model deployment: Deploy the trained model in a production environment and monitor its performance.\n",
    "\n",
    "- Model maintenance: Continuously evaluate and update the model as new data becomes available to ensure it remains accurate.\n",
    "\n",
    "This lifecycle may repeat as the problem and data evolve over time, requiring the model to be retrained and updated accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a71852",
   "metadata": {},
   "source": [
    "### Q15. What is the necessity of understanding the problem statement and creating a well defined architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52082e",
   "metadata": {},
   "source": [
    "Understanding the problem statement and creating a well-defined architecture are crucial steps in the machine learning process for several reasons:\n",
    "\n",
    "Problem Definition: A clear understanding of the problem helps to set the direction for the development of the machine learning system. It defines the goals and objectives of the system, and provides information about the available data and the desired output. This helps to ensure that the machine learning system is developed to solve the right problem.\n",
    "\n",
    "Model Selection: A well-defined problem statement helps to determine the appropriate type of machine learning model for the task. This includes selecting a model type that is suitable for the problem, and evaluating different models to select the one with the best performance.\n",
    "\n",
    "Feature Engineering: A well-defined problem statement helps to guide the feature engineering process, which involves selecting and transforming the most relevant features for the problem. Feature engineering is a crucial step in the machine learning process, as the quality of the features used by the model has a significant impact on its performance.\n",
    "\n",
    "Model Development: A well-defined architecture helps to ensure that the machine learning system is developed according to a structured plan, which makes the development process more efficient and effective. A well-defined architecture provides a roadmap for the development of the machine learning system, and helps to ensure that all components of the system are integrated and working together as intended.\n",
    "\n",
    "Deployment: A well-defined architecture helps to ensure that the machine learning system can be deployed and integrated with other systems in a real-world environment. A well-defined architecture also makes it easier to monitor the performance of the deployed machine learning system, and to perform regular maintenance tasks to keep the system up-to-date.\n",
    "\n",
    "In summary, understanding the problem statement and creating a well-defined architecture are essential steps in the machine learning process that help to ensure that the system is developed to solve the right problem, that it is developed in an efficient and effective manner, and that it can be deployed and integrated with other systems in a real-world environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ff894",
   "metadata": {},
   "source": [
    "### Q16. Why do we create a separate workspace for every problem statement?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09503275",
   "metadata": {},
   "source": [
    "Creating a separate workspace for every problem statement is a best practice in machine learning because it allows you to maintain a clear separation of the data, models, and results associated with each problem. This helps to avoid confusion and make it easier to track the progress of each problem and collaborate with others.\n",
    "\n",
    "A separate workspace also makes it easier to manage the resources required for each problem, such as computing resources, storage, and memory. This can help to avoid resource contention and ensure that each problem has the resources it needs to run effectively.\n",
    "\n",
    "In addition, using separate workspaces for each problem can facilitate reproducibility. This is because all the data, models, and results for each problem are stored in a single place, making it easy to recreate the results and share them with others.\n",
    "\n",
    "Overall, creating a separate workspace for every problem statement is a key aspect of organizing and managing machine learning projects and is an essential part of the machine learning development lifecycle.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc226d20",
   "metadata": {},
   "source": [
    "### Q17. What are the different sources which can be used as a source of data gathering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9718c9",
   "metadata": {},
   "source": [
    "There are many sources of data that can be used for machine learning. Some common sources include:\n",
    "\n",
    "    1.Structured data: This includes data that is stored in a well-defined format, such as spreadsheets, databases, and tables.\n",
    "\n",
    "    2.Unstructured data: This includes data that does not have a well-defined format, such as text, images, audio, and video.\n",
    "\n",
    "    3.Semi-structured data: This includes data that has some structure, but not as much as structured data, such as XML and JSON files.\n",
    "\n",
    "    4.External data: This includes data that is obtained from external sources, such as public data sources, APIs, and commercial data providers.\n",
    "\n",
    "    5.Internal data: This includes data that is generated within an organization, such as customer data, financial data, and sensor data.\n",
    "\n",
    "    6.Crowdsourced data: This includes data that is collected from large groups of people, such as survey responses and social media posts.\n",
    "\n",
    "The choice of data source depends on the problem to be solved, the data that is available, and the goals of the machine learning project. It is important to carefully consider the quality, accuracy, and completeness of the data before using it for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb0fd7",
   "metadata": {},
   "source": [
    "### Q18. What is the data annotation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed4d50",
   "metadata": {},
   "source": [
    "Data annotation is the process of adding labels or tags to data to provide context and meaning. In machine learning, data annotation is used to create labeled training data sets, which are used to train models.\n",
    "\n",
    "Data annotation can involve adding class labels to data points, such as classifying an image as a \"dog\" or a \"cat\". It can also involve adding other types of information, such as bounding boxes around objects in an image or transcribing audio to text.\n",
    "\n",
    "The goal of data annotation is to make the data more useful for machine learning by providing additional information about the data that can be used to train models. Data annotation is a time-consuming and labor-intensive process, but it is essential for building accurate machine learning models.\n",
    "\n",
    "Data annotation can be performed manually by human annotators or using automated tools, such as computer vision algorithms or speech recognition software. The choice of method depends on the type of data, the accuracy requirements, and the resources available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb71ed9",
   "metadata": {},
   "source": [
    "### Q19. What are the different steps involved in data wrangling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a470e99",
   "metadata": {},
   "source": [
    "Data wrangling, also known as data munging, is the process of cleaning, transforming, and preparing data for analysis or modeling. The following are the common steps involved in data wrangling:\n",
    "\n",
    "Data acquisition: Obtain the data from various sources, such as databases, APIs, or spreadsheets.\n",
    "\n",
    "Data inspection: Examine the data to understand its structure, quality, and potential issues.\n",
    "\n",
    "Data cleaning: Remove or correct inaccuracies, inconsistencies, and missing values in the data.\n",
    "\n",
    "Data transformation: Convert the data into a format that is suitable for analysis or modeling, such as converting text to numerical values.\n",
    "\n",
    "Data normalization: Transform the data into a standard format, such as scaling values to a common range.\n",
    "\n",
    "Data aggregation: Combine multiple data sources into a single data set, such as combining customer data from multiple databases.\n",
    "\n",
    "Data visualization: Create visualizations of the data to gain insights and understand patterns.\n",
    "\n",
    "These steps may need to be repeated multiple times until the data is in a clean and usable form. Data wrangling is an important step in the machine learning process as the quality of the data used for modeling can have a significant impact on the accuracy of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d452f",
   "metadata": {},
   "source": [
    "### Q20. What are the steps involved in model development?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de041e",
   "metadata": {},
   "source": [
    "The steps involved in model development in machine learning are as follows:\n",
    "\n",
    "Problem definition: Clearly define the problem you are trying to solve and the goals of the model.\n",
    "\n",
    "Data preparation: Gather, clean, and preprocess the data for modeling. This may include data wrangling, feature engineering, and data splitting.\n",
    "\n",
    "Model selection: Choose a model type that is suitable for the problem, such as linear regression, decision trees, or neural networks.\n",
    "\n",
    "Model training: Train the model using the preprocessed data. This involves adjusting the model parameters to minimize the error between the model's predictions and the actual values.\n",
    "\n",
    "Model evaluation: Evaluate the performance of the model using metrics such as accuracy, precision, recall, and F1 score. Compare the performance of the model to the baseline and to other models.\n",
    "\n",
    "Model tuning: Adjust the model hyperparameters to improve its performance. This may involve trying different models, changing the learning rate, or adding regularization.\n",
    "\n",
    "Model deployment: Deploy the model in a production environment, such as an API or a mobile app.\n",
    "\n",
    "Model monitoring: Continuously monitor the performance of the model in production and update it as needed.\n",
    "\n",
    "These steps may need to be repeated multiple times until the best model for the problem is obtained. Model development is an iterative process, and it is important to continually evaluate and improve the model as new data and insights become available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c495077",
   "metadata": {},
   "source": [
    "### Q21. What are the different steps involved in model training?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b561258",
   "metadata": {},
   "source": [
    "The steps involved in model training in machine learning are as follows:\n",
    "\n",
    "1. Data preparation: Gather and preprocess the data that will be used to train the model. This may include data wrangling, feature engineering, and data splitting.\n",
    "\n",
    "2. Model selection: Choose a model type that is suitable for the problem, such as linear regression, decision trees, or neural networks.\n",
    "\n",
    "3. Model initialization: Set the initial values for the model parameters.\n",
    "\n",
    "4. Model optimization: Adjust the model parameters to minimize the error between the model's predictions and the actual values. This may involve using optimization algorithms such as gradient descent or stochastic gradient descent.\n",
    "\n",
    "5. Model evaluation: Evaluate the performance of the model on the training data using metrics such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "6. Model refinement: Refine the model by adjusting the hyperparameters, trying different models, or adding regularization.\n",
    "\n",
    "7. Model validation: Evaluate the performance of the model on a separate validation data set to assess its generalization performance.\n",
    "\n",
    "These steps are typically repeated multiple times until the best model for the problem is obtained. Model training is a crucial step in the machine learning process as it determines the accuracy and performance of the model. The quality of the training data and the choice of model type and hyperparameters can have a significant impact on the performance of the model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc90bcfb",
   "metadata": {},
   "source": [
    "### Q22. What is hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e43e13",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is the process of adjusting the hyperparameters of a machine learning model to improve its performance. Hyperparameters are parameters that are not learned from the data, but set prior to training the model. Examples of hyperparameters include the learning rate, the number of hidden layers in a neural network, or the regularization coefficient.\n",
    "\n",
    "The goal of hyperparameter tuning is to find the best values for the hyperparameters that produce the best model performance. This is usually done by training multiple models with different hyperparameter values and evaluating their performance on a validation data set. The hyperparameters that produce the best performance are then used to train the final model.\n",
    "\n",
    "Hyperparameter tuning is a crucial step in the machine learning process, as the choice of hyperparameters can have a significant impact on the performance of the model. The performance of the model can be improved by fine-tuning the hyperparameters to better match the characteristics of the data. However, hyperparameter tuning can be time-consuming and computationally expensive, so it is important to be efficient and methodical when tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb76a4c",
   "metadata": {},
   "source": [
    "### Q22. What are the different steps involved in model evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5786508f",
   "metadata": {},
   "source": [
    "The steps involved in model evaluation in machine learning are as follows:\n",
    "\n",
    "Data preparation: Gather and preprocess the data that will be used to evaluate the model. This may include data wrangling, feature engineering, and data splitting.\n",
    "\n",
    "Model selection: Choose a model type that is suitable for the problem, such as linear regression, decision trees, or neural networks.\n",
    "\n",
    "Model training: Train the model on the data.\n",
    "\n",
    "Metric selection: Choose the appropriate evaluation metrics for the problem, such as accuracy, precision, recall, F1 score, or ROC curve.\n",
    "\n",
    "Model evaluation: Evaluate the performance of the model on the evaluation data using the selected metrics. Compare the performance of the model to the baseline and to other models.\n",
    "\n",
    "Model refinement: Refine the model based on the evaluation results by adjusting the hyperparameters, trying different models, or adding regularization.\n",
    "\n",
    "These steps are typically repeated multiple times until the best model for the problem is obtained. Model evaluation is an important step in the machine learning process as it allows you to assess the performance of the model and identify areas for improvement. It is crucial to use appropriate evaluation metrics and to evaluate the model on a separate data set to assess its generalization performance.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9054f68b",
   "metadata": {},
   "source": [
    "### Q23. What is model over fitting and under fitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ae0a5",
   "metadata": {},
   "source": [
    "Overfitting and underfitting are common issues in machine learning.\n",
    "\n",
    "Overfitting occurs when a model is too complex and learns the noise in the data instead of the underlying pattern. As a result, the model performs well on the training data but poorly on new, unseen data. Overfitting is typically caused by having too many parameters in the model, or by training the model for too long.\n",
    "\n",
    "Underfitting occurs when a model is too simple and cannot capture the complexity of the relationship between the features and the target. As a result, the model has high bias and performs poorly on both the training and new data. Underfitting is typically caused by having too few parameters in the model or by using a model that is not appropriate for the problem.\n",
    "\n",
    "Both overfitting and underfitting can be addressed by adjusting the model hyperparameters, using regularization techniques, or using a different model architecture. Cross-validation and early stopping are common techniques used to prevent overfitting in the training process. Model evaluation on a separate validation set is also an important step in detecting overfitting and underfitting.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5095a591",
   "metadata": {},
   "source": [
    "### Q24. What is model deployment?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f9a141",
   "metadata": {},
   "source": [
    "Model deployment refers to the process of making a machine learning model accessible and usable in a real-world environment. It involves taking the trained model and putting it into a production environment where it can be used to make predictions on new data.\n",
    "\n",
    "There are several steps involved in deploying a machine learning model:\n",
    "\n",
    "Model preparation: Prepare the model for deployment by ensuring that it is in the correct format and that any required libraries and dependencies are available.\n",
    "\n",
    "Model hosting: Host the model on a server or cloud platform that can provide access to the model from a variety of devices and applications.\n",
    "\n",
    "API creation: Create an API (Application Programming Interface) that allows users to access the model and make predictions. This can be done using web services or by building a custom API.\n",
    "\n",
    "Model monitoring: Monitor the performance of the model in production and make adjustments as needed.\n",
    "\n",
    "Model maintenance: Maintain the model by updating it with new data, fixing bugs, or making performance improvements.\n",
    "\n",
    "Deploying a machine learning model is a critical step in the machine learning process as it allows the model to be used to make predictions in a real-world environment. It is important to ensure that the deployed model is secure, reliable, and accessible to the users who need it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0ebaa4",
   "metadata": {},
   "source": [
    "### Q25. What are the different sources where we can deploy our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2812d7f4",
   "metadata": {},
   "source": [
    "There are several sources where you can deploy your machine learning model, including:\n",
    "\n",
    "On-premise servers: You can deploy your model on your own physical servers in your own data center.\n",
    "\n",
    "Cloud platforms: You can deploy your model on cloud platforms like Amazon Web Services (AWS), Google Cloud Platform (GCP), or Microsoft Azure.\n",
    "\n",
    "Containers: You can deploy your model in containers, such as Docker or Kubernetes, to ensure that the model is isolated and runs consistently across different environments.\n",
    "\n",
    "Mobile devices: You can deploy your model on mobile devices, such as smartphones or tablets, allowing the model to be used in a variety of locations and environments.\n",
    "\n",
    "Web applications: You can deploy your model in a web application, allowing users to access the model and make predictions through a web browser.\n",
    "\n",
    "The choice of deployment source will depend on the requirements of the project, such as the desired scalability, security, and cost, as well as the available resources and technical expertise. Some deployment sources may be more appropriate for certain use cases than others.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7b4c07",
   "metadata": {},
   "source": [
    "### Q26. What is model monitoring and how can we do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d8efe",
   "metadata": {},
   "source": [
    "Model monitoring is the process of regularly checking the performance of a deployed machine learning model to ensure that it is working as expected and delivering the desired results. This is important because the performance of a model can deteriorate over time due to changes in the data distribution or other factors.\n",
    "\n",
    "There are several ways to monitor a machine learning model, including:\n",
    "\n",
    "Performance metrics: Monitor the performance of the model using metrics such as accuracy, precision, recall, and F1 score. Compare the performance of the model over time to detect any changes or deterioration.\n",
    "\n",
    "Logging: Log the predictions made by the model, as well as the input features and other relevant information. This can be used to identify any problems or issues with the model.\n",
    "\n",
    "Alerts: Set up alerts to notify you if the performance of the model drops below a certain threshold or if there are any other issues with the model.\n",
    "\n",
    "A/B testing: Use A/B testing to compare the performance of the deployed model with a new version of the model or with a different model entirely. This can help you to identify any improvements that can be made to the model.\n",
    "\n",
    "Model retraining: Regularly retrain the model on new data to ensure that it continues to perform well.\n",
    "\n",
    "It is important to regularly monitor the performance of a deployed machine learning model to ensure that it is delivering the desired results and to identify any issues that need to be addressed. Model monitoring can help to ensure that the model remains accurate, relevant, and useful over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8222be",
   "metadata": {},
   "source": [
    "### Q27. What is model retraining?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c7b108",
   "metadata": {},
   "source": [
    "Model retraining is the process of updating a machine learning model with new data to improve its performance. This is important because the distribution of the data can change over time, causing the model's performance to deteriorate. By retraining the model on new data, you can help to ensure that it continues to deliver accurate predictions.\n",
    "\n",
    "There are several steps involved in retraining a machine learning model:\n",
    "\n",
    "Data collection: Gather new data that can be used to retrain the model. This data should be relevant and representative of the current data distribution.\n",
    "\n",
    "Data preprocessing: Preprocess the new data to prepare it for use in the model. This may involve cleaning, transforming, or normalizing the data.\n",
    "\n",
    "Model retraining: Train the model on the new data using the same or similar algorithms and techniques as used previously.\n",
    "\n",
    "Model evaluation: Evaluate the performance of the retrained model to determine if it has improved or not.\n",
    "\n",
    "Model deployment: Deploy the retrained model in a production environment, replacing the previous model.\n",
    "\n",
    "Retraining a machine learning model is an important step in maintaining the accuracy and relevance of the model over time. It should be done regularly, particularly when there are significant changes in the data distribution or when the performance of the model begins to deteriorate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee7b9a",
   "metadata": {},
   "source": [
    "### Q28. What are the conditions when we need to do model retraining?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5295f8",
   "metadata": {},
   "source": [
    "There are several conditions that may indicate that it is necessary to retrain a machine learning model:\n",
    "\n",
    "Data distribution change: If the distribution of the data used by the model has changed, the model's performance may deteriorate. In this case, retraining the model on new data that reflects the current distribution can help to improve its performance.\n",
    "\n",
    "Model performance degradation: Over time, the performance of a machine learning model can deteriorate due to factors such as changes in the data distribution, concept drift, or the accumulation of errors. If the model's performance drops significantly, it may be necessary to retrain it.\n",
    "\n",
    "New data availability: If new data becomes available that is relevant to the problem being solved by the model, retraining the model on this data can improve its accuracy and relevance.\n",
    "\n",
    "Model outdatedness: If the model was trained on outdated data or if the underlying algorithms used by the model have become outdated, it may be necessary to retrain the model using new algorithms or techniques.\n",
    "\n",
    "Model improvement opportunities: If new techniques or algorithms become available that have the potential to improve the performance of the model, retraining the model using these new techniques can lead to improved results.\n",
    "\n",
    "Retraining a machine learning model is an important step in maintaining its accuracy and relevance over time. It should be done regularly, particularly when there are significant changes in the data distribution or when the performance of the model begins to deteriorate. The specific conditions that warrant retraining will depend on the specific problem being solved and the data being used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64d9f53",
   "metadata": {},
   "source": [
    "### Q29. Download the [housing data](https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html) and train a machine learning model and can be used to predict the price of house given the required parameters.\n",
    "- Try creating a single pipeline that does every steps from data preparation to model prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d9ee68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "california=fetch_california_housing()\n",
    "dir(california)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e67a5458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "california.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc417b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('.. _california_housing_dataset:\\n'\n",
      " '\\n'\n",
      " 'California Housing dataset\\n'\n",
      " '--------------------------\\n'\n",
      " '\\n'\n",
      " '**Data Set Characteristics:**\\n'\n",
      " '\\n'\n",
      " '    :Number of Instances: 20640\\n'\n",
      " '\\n'\n",
      " '    :Number of Attributes: 8 numeric, predictive attributes and the target\\n'\n",
      " '\\n'\n",
      " '    :Attribute Information:\\n'\n",
      " '        - MedInc        median income in block group\\n'\n",
      " '        - HouseAge      median house age in block group\\n'\n",
      " '        - AveRooms      average number of rooms per household\\n'\n",
      " '        - AveBedrms     average number of bedrooms per household\\n'\n",
      " '        - Population    block group population\\n'\n",
      " '        - AveOccup      average number of household members\\n'\n",
      " '        - Latitude      block group latitude\\n'\n",
      " '        - Longitude     block group longitude\\n'\n",
      " '\\n'\n",
      " '    :Missing Attribute Values: None\\n'\n",
      " '\\n'\n",
      " 'This dataset was obtained from the StatLib repository.\\n'\n",
      " 'https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n'\n",
      " '\\n'\n",
      " 'The target variable is the median house value for California districts,\\n'\n",
      " 'expressed in hundreds of thousands of dollars ($100,000).\\n'\n",
      " '\\n'\n",
      " 'This dataset was derived from the 1990 U.S. census, using one row per '\n",
      " 'census\\n'\n",
      " 'block group. A block group is the smallest geographical unit for which the '\n",
      " 'U.S.\\n'\n",
      " 'Census Bureau publishes sample data (a block group typically has a '\n",
      " 'population\\n'\n",
      " 'of 600 to 3,000 people).\\n'\n",
      " '\\n'\n",
      " 'An household is a group of people residing within a home. Since the average\\n'\n",
      " 'number of rooms and bedrooms in this dataset are provided per household, '\n",
      " 'these\\n'\n",
      " 'columns may take surpinsingly large values for block groups with few '\n",
      " 'households\\n'\n",
      " 'and many empty houses, such as vacation resorts.\\n'\n",
      " '\\n'\n",
      " 'It can be downloaded/loaded using the\\n'\n",
      " ':func:`sklearn.datasets.fetch_california_housing` function.\\n'\n",
      " '\\n'\n",
      " '.. topic:: References\\n'\n",
      " '\\n'\n",
      " '    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n'\n",
      " '      Statistics and Probability Letters, 33 (1997) 291-297\\n')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pp\n",
    "pp(california.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f701b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(data=california.data,columns=california.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8aa9332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedHouseVal']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2089030e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the housing data into a pandas dataframe\n",
    "df[california.target_names[0]]=california.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d612944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.2787073274407389\n",
      "R2 Scored  0.7934860911581435\n"
     ]
    }
   ],
   "source": [
    "# Clean and preprocess the data as necessary\n",
    "df.dropna(inplace=True)\n",
    "df = pd.get_dummies(df)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('MedHouseVal', axis=1), df['MedHouseVal'], test_size=0.2)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train the model on the training data\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error of the predictions\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calcuate the r2 score\n",
    "r2 =r2_score(y_test,y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print('R2 Scored ',r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846c65b",
   "metadata": {},
   "source": [
    "## EXTRA Ques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d7784",
   "metadata": {},
   "source": [
    "### - E01: is there any similiraty between data augumentation and annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c291b8",
   "metadata": {},
   "source": [
    "Data augmentation and annotation are related but distinct processes in machine learning.\n",
    "\n",
    "Data augmentation involves creating new data samples from existing data samples, usually by applying various transformations such as rotation, scaling, and flipping. The purpose of data augmentation is to increase the size of the dataset and to improve the robustness of a machine learning model.\n",
    "\n",
    "Data annotation, on the other hand, involves labeling or annotating data samples with descriptive or categorical information. The purpose of data annotation is to provide ground-truth information for training machine learning models or for evaluating their performance.\n",
    "\n",
    "So, while both data augmentation and annotation can be used to improve the quality of data for machine learning, they are distinct processes that serve different purposes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca098f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
